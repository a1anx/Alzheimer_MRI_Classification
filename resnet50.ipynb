{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andykim/Documents/2025 Fall/NNDL/Project/NNDL_MRI_PROJECT/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 6735 files [00:01, 3428.20 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete\n",
      "================================================================================\n",
      "IMAGE COUNT PER SPLIT PER CLASS\n",
      "================================================================================\n",
      "\n",
      "TRAIN:\n",
      "--------------------------------------------------------------------------------\n",
      "  Brain - Alzheimer MildDemented                       1399 images\n",
      "  Brain - Alzheimer ModerateDemented                   1139 images\n",
      "  Brain - Alzheimer NonDemented                        1653 images\n",
      "  Brain - Alzheimer VeryMildDemented                   1196 images\n",
      "  --------------------------------------------------\n",
      "  TOTAL                                                5387 images\n",
      "\n",
      "VAL:\n",
      "--------------------------------------------------------------------------------\n",
      "  Brain - Alzheimer MildDemented                        174 images\n",
      "  Brain - Alzheimer ModerateDemented                    142 images\n",
      "  Brain - Alzheimer NonDemented                         206 images\n",
      "  Brain - Alzheimer VeryMildDemented                    149 images\n",
      "  --------------------------------------------------\n",
      "  TOTAL                                                 671 images\n",
      "\n",
      "TEST:\n",
      "--------------------------------------------------------------------------------\n",
      "  Brain - Alzheimer MildDemented                        176 images\n",
      "  Brain - Alzheimer ModerateDemented                    143 images\n",
      "  Brain - Alzheimer NonDemented                         208 images\n",
      "  Brain - Alzheimer VeryMildDemented                    150 images\n",
      "  --------------------------------------------------\n",
      "  TOTAL                                                 677 images\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SUMMARY TABLE:\n",
      "================================================================================\n",
      "Class                                                 Train      Val     Test    Total\n",
      "--------------------------------------------------------------------------------\n",
      "Brain - Alzheimer MildDemented                         1399      174      176     1749\n",
      "Brain - Alzheimer ModerateDemented                     1139      142      143     1424\n",
      "Brain - Alzheimer NonDemented                          1653      206      208     2067\n",
      "Brain - Alzheimer VeryMildDemented                     1196      149      150     1495\n",
      "--------------------------------------------------------------------------------\n",
      "Total count across all classes:  6735\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "import os\n",
    "\n",
    "# Assign 4 classes of MRI images (MildDemented, ModerateDemented, NonDemented, VeryMildDemented) randomly and evenly as train, validation, and test data\n",
    "splitfolders.ratio(\n",
    "    \"/Users/andykim/Documents/2025 Fall/NNDL/Project/NNDL_MRI_PROJECT/Augmented_Data\",\n",
    "    output=\"/Users/andykim/Documents/2025 Fall/NNDL/Project/NNDL_MRI_PROJECT/Split_Data\",\n",
    "    seed=1337,\n",
    "    ratio=(.8, .1, .1)\n",
    ")\n",
    "\n",
    "print(\"Split complete\")\n",
    "\n",
    "# Check the distribution of MRI images\n",
    "\n",
    "split_data_path = \"/Users/andykim/Documents/2025 Fall/NNDL/Project/NNDL_MRI_PROJECT/Split_Data\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IMAGE COUNT PER SPLIT PER CLASS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(split_data_path, split)\n",
    "    \n",
    "    if not os.path.exists(split_path):\n",
    "        print(f\"\\n{split.upper()}: Folder not found!\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total = 0\n",
    "    classes = sorted(os.listdir(split_path))\n",
    "    \n",
    "    for class_name in classes:\n",
    "        if class_name == '.DS_Store':\n",
    "            continue\n",
    "            \n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if not f.startswith('.')])\n",
    "            total += count\n",
    "            print(f\"  {class_name:50s} {count:6d} images\")\n",
    "    \n",
    "    print(f\"  {'-' * 50}\")\n",
    "    print(f\"  {'TOTAL':50s} {total:6d} images\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nSUMMARY TABLE:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Class':<50s} {'Train':>8s} {'Val':>8s} {'Test':>8s} {'Total':>8s}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "classes = []\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(split_data_path, split)\n",
    "    if os.path.exists(split_path):\n",
    "        classes = sorted([c for c in os.listdir(split_path) if c != '.DS_Store' and os.path.isdir(os.path.join(split_path, c))])\n",
    "        break\n",
    "\n",
    "full_total = 0\n",
    "for class_name in classes:\n",
    "    counts = []\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        class_path = os.path.join(split_data_path, split, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if not f.startswith('.')])\n",
    "            counts.append(count)\n",
    "        else:\n",
    "            counts.append(0)\n",
    "    \n",
    "    total = sum(counts)\n",
    "    print(f\"{class_name:<50s} {counts[0]:8d} {counts[1]:8d} {counts[2]:8d} {total:8d}\")\n",
    "    full_total += total\n",
    "print(\"-\" * 80)\n",
    "print(\"Total count across all classes: \", full_total)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: keras in ./venv/lib/python3.13/site-packages (3.12.0)\n",
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.13/site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.13/site-packages (from keras) (14.2.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.13/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in ./venv/lib/python3.13/site-packages (from keras) (3.15.1)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.13/site-packages (from keras) (0.18.0)\n",
      "Requirement already satisfied: ml-dtypes in ./venv/lib/python3.13/site-packages (from keras) (0.5.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./venv/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./venv/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./venv/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./venv/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run the following command \n",
    "pip install numpy pandas scikit-learn matplotlib seaborn keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.applications.resnet import ResNet50 \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch size:  32   test steps:  1\n",
      "Found 5387 images belonging to 4 classes.\n",
      "Found 677 images belonging to 4 classes.\n",
      "Found 671 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "channels=3\n",
    "batch_size=25\n",
    "test_batch_size=32 \n",
    "test_steps=1\n",
    "train_path = './Split_Data/train'\n",
    "test_path = './Split_Data/test'\n",
    "val_path = './Split_Data/val'\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "def scalar(img):    \n",
    "    return img  # EfficientNet expects pixelsin range 0 to 255 so no scaling is required\n",
    "trgen=ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n",
    "tvgen=ImageDataGenerator(preprocessing_function=scalar)\n",
    "train_generator=trgen.flow_from_directory( directory=train_path , target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "test_generator=tvgen.flow_from_directory( directory=test_path, target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "valid_generator=tvgen.flow_from_directory( directory=val_path, target_size=(224,224), class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "classes=list(train_generator.class_indices.keys())\n",
    "class_count=len(classes)\n",
    "train_steps=int(np.ceil(len(train_generator.labels)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
